{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR HF 推理与后验采样 Demo\n",
    "\n",
    "本 Notebook 展示了如何：\n",
    "\n",
    "1. 从 Hugging Face (`FoundationVision/var`) 下载官方发布的 VAE 与 VAR 权重；\n",
    "2. 构建 `var_inv` 中自带的 VAR/VQVAE 模型，并使用 `VAR.autoregressive_infer_cfg` 进行标准 CFG 采样；\n",
    "3. 借助 `GradientGuidedVARSampler` + 测量算子，将 VAR 视作“离散扩散”，对部分观测数据执行后验重建，并可视化每个尺度的重建过程。\n",
    "\n",
    "> ⚠️ 运行前请确保你拥有 Hugging Face 的下载权限（可能需要 `huggingface-cli login`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备依赖与工具函数\n",
    "\n",
    "以下代码导入 `var_inv` 中封装好的模块，并提供若干辅助函数用于读写图片、可视化采样结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "\n",
    "from var_inv.measurements import MaskingMeasurement\n",
    "from var_inv.posterior_sampling import (\n",
    "    GradientGuidedVARSampler,\n",
    "    MeasurementModel,\n",
    "    PosteriorGuidanceConfig,\n",
    ")\n",
    "from var_inv.var_models.models import build_vae_var\n",
    "\n",
    "\n",
    "def load_rgb(path: Path, target_hw: int) -> torch.Tensor:\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    if target_hw is not None:\n",
    "        img = img.resize((target_hw, target_hw), Image.BICUBIC)\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "\n",
    "def tensor_to_pil(t: torch.Tensor) -> Image.Image:\n",
    "    t = t.detach().cpu().clamp(0, 1)\n",
    "    if t.ndim == 4:\n",
    "        t = t[0]\n",
    "    arr = (t.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "\n",
    "def show_tensor(t: torch.Tensor, title: str = \"\") -> None:\n",
    "    pil_img = tensor_to_pil(t)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(pil_img)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_stages(stage_imgs: List[torch.Tensor], ncols: int = 5) -> None:\n",
    "    if not stage_imgs:\n",
    "        return\n",
    "    nrows = math.ceil(len(stage_imgs) / ncols)\n",
    "    plt.figure(figsize=(3 * ncols, 3 * nrows))\n",
    "    for idx, stage in enumerate(stage_imgs):\n",
    "        ax = plt.subplot(nrows, ncols, idx + 1)\n",
    "        ax.imshow(tensor_to_pil(stage))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"Stage {idx+1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 下载 Hugging Face 权重\n",
    "\n",
    "我们以 `VAR-d16` 为例，需要同时下载 `vae_ch160v4096z32.pth` 与 `var_d16.pth`。下载后的文件会缓存在 `var_inv/hf_assets/` 目录，方便重复运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEPTH = 16  # 可切换成 20/24/30/36，对应不同体量的模型\n",
    "REPO_ID = \"FoundationVision/var\"\n",
    "HF_CACHE = Path(\"var_inv/hf_assets\")\n",
    "HF_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "vae_path = hf_hub_download(repo_id=REPO_ID, filename=\"vae_ch160v4096z32.pth\", cache_dir=HF_CACHE)\n",
    "var_path = hf_hub_download(repo_id=REPO_ID, filename=f\"var_d{MODEL_DEPTH}.pth\", cache_dir=HF_CACHE)\n",
    "print(f\"VAE ckpt: {vae_path}\\nVAR ckpt: {var_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建 VAE / VAR 并加载权重\n",
    "\n",
    "`build_vae_var` 会创建和官方实现一致的结构。加载权重时，我们针对不同 checkpoint 格式（`model`/`state_dict`/纯 `state_dict`）做了兼容处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
    "\n",
    "vae, var = build_vae_var(\n",
    "    device=device,\n",
    "    patch_nums=patch_nums,\n",
    "    num_classes=1000,\n",
    "    depth=MODEL_DEPTH,\n",
    "    shared_aln=False,\n",
    "    attn_l2_norm=True,\n",
    ")\n",
    "\n",
    "def load_module_state(module: torch.nn.Module, ckpt_path: str) -> None:\n",
    "    payload = torch.load(ckpt_path, map_location=device)\n",
    "    if isinstance(payload, dict) and \"state_dict\" in payload:\n",
    "        payload = payload[\"state_dict\"]\n",
    "    if isinstance(payload, dict) and \"model\" in payload:\n",
    "        payload = payload[\"model\"]\n",
    "    module.load_state_dict(payload, strict=True)\n",
    "\n",
    "load_module_state(vae, vae_path)\n",
    "load_module_state(var, var_path)\n",
    "\n",
    "vae.eval().requires_grad_(False)\n",
    "var.eval().requires_grad_(False)\n",
    "print(\"Models are ready on\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 直接使用 CFG 采样\n",
    "\n",
    "首先展示最基础的用法：根据 ImageNet 分类标签直接生成图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "label = torch.tensor([207], device=device)  # 例如 \"golden retriever\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    autocast = torch.autocast(device_type=device.type, enabled=device.type == \"cuda\", dtype=torch.float16)\n",
    "    with autocast:\n",
    "        sample = var.autoregressive_infer_cfg(\n",
    "            B=label.shape[0],\n",
    "            label_B=label,\n",
    "            g_seed=seed,\n",
    "            cfg=4.0,\n",
    "            top_k=900,\n",
    "            top_p=0.96,\n",
    "            more_smooth=False,\n",
    "        )\n",
    "\n",
    "show_tensor(sample, title=\"CFG Sampling Result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 观测约束 + 梯度引导后验采样\n",
    "\n",
    "下面示例模拟一个“随机遮挡”的测量：我们取一张现有图片，当作观测 `y = M \\odot x`，其中 `M` 是随机掩膜。`GradientGuidedVARSampler` 会在每个尺度上通过 Gumbel-Softmax 计算梯度，指导 logits 满足测量约束，并记录每个尺度的重建结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = Path(\"diffusion-posterior-sampling/data/samples/00014.png\")  # 可替换成任意 RGB 图\n",
    "target_hw = patch_nums[-1] * vae.downsample  # 16 * 16 = 256\n",
    "reference = load_rgb(reference_path, target_hw).to(device)\n",
    "\n",
    "mask = MaskingMeasurement.random(\n",
    "    shape=(1, 1, target_hw, target_hw),\n",
    "    keep_ratio=0.35,\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ").to(device)\n",
    "measurement_model = MeasurementModel(operator=mask.operator, filter_fn=lambda x, _: x)\n",
    "measurement = measurement_model.measure(reference)\n",
    "\n",
    "# 预计算已知区域的 GT token（anchor），只在 mask==1 的位置强制替换\n",
    "ref_norm = reference * 2 - 1\n",
    "anchor_tokens = var.vae_proxy[0].img_to_idxBl(ref_norm, v_patch_nums=var.vae_quant_proxy[0].v_patch_nums)\n",
    "token_constraints = []\n",
    "mask_tensor = mask.mask  # (B,1,H,W)\n",
    "for si, pn in enumerate(var.vae_quant_proxy[0].v_patch_nums):\n",
    "    m_stage = torch.nn.functional.interpolate(mask_tensor, size=(pn, pn), mode=\"area\")\n",
    "    m_stage = (m_stage > 0.5).squeeze(1)  # B x pn x pn -> B x pn x pn\n",
    "    token_constraints.append({\"mask\": m_stage.reshape(mask_tensor.shape[0], -1), \"idx\": anchor_tokens[si]})\n",
    "\n",
    "cfg_params = PosteriorGuidanceConfig(\n",
    "    cfg_scale=0.0,          # 关闭 CFG，完全依赖观测\n",
    "    grad_scale_min=0.5,\n",
    "    grad_scale_max=2.0,\n",
    "    grad_start_ratio=0.0,\n",
    "    grad_steps=5,\n",
    "    grad_stop_before_stage=5,  # 前半段不做梯度，靠 token 注入固定结构\n",
    "    top_p=0.0,\n",
    "    top_k=0,\n",
    ")\n",
    "sampler = GradientGuidedVARSampler(var_model=var, measurement_model=measurement_model, config=cfg_params)\n",
    "\n",
    "result = sampler.sample(\n",
    "    measurement=measurement,\n",
    "    label_B=-1,   # -1 表示完全无条件\n",
    "    g_seed=seed,\n",
    "    capture_intermediate=True,\n",
    "    capture_token_trace=True,\n",
    "    token_constraints=token_constraints,\n",
    ")\n",
    "if len(result) == 3:\n",
    "    recon, stage_imgs, token_trace = result\n",
    "else:\n",
    "    recon, stage_imgs = result\n",
    "    token_trace = []\n",
    "\n",
    "masked_recon = mask.operator(recon.to(device))\n",
    "mse_mask = torch.nn.functional.mse_loss(masked_recon, measurement)\n",
    "print(f\"Masked-region MSE: {mse_mask.item():.5f}\")\n",
    "\n",
    "for info in token_trace:\n",
    "    diff = (info[\"cfg_top\"] != info[\"guided_top\"]).sum().item()\n",
    "    total = info[\"cfg_top\"].numel()\n",
    "    forced = info.get(\"forced_tokens\", 0)\n",
    "    print(\n",
    "        f\"Stage {info['stage']}: changed {diff}/{total} tokens, \"\n",
    "        f\"grad_norm={info['grad_norm']:.4f}, max_delta={info['max_delta']:.4f}, forced={forced}\"\n",
    "    )\n",
    "\n",
    "show_tensor(reference, title=\"Ground Truth (x)\")\n",
    "show_tensor(measurement, title=\"Measurement (y = M ⊙ x)\")\n",
    "show_tensor(recon, title=\"Posterior Reconstruction\")\n",
    "visualize_stages(stage_imgs, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上可视化了从 coarse-to-fine 的每个尺度输出，呈现 VAR 作为“离散扩散”时的逐步细化效果。你也可以尝试其他测量（模糊、超分辨率等）或替换标签、随机种子，探索梯度引导对后验采样的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 其他测量算子快速测试\n",
    "\n",
    "下面再用模糊、超分辨率两种测量跑一遍，以验证梯度引导是否对不同 operator 生效。这里不做 token 硬注入，只用频域引导+随机标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from var_inv.measurements import GaussianBlurMeasurement, SuperResolutionMeasurement\n",
    "\n",
    "def run_operator_test(measure_op, name: str):\n",
    "    # 对于模糊/超分，默认整张图都是已知区域：前半段硬注入 GT token，后半段用梯度微调。\n",
    "    measurement_model = MeasurementModel(operator=measure_op.operator, filter_fn=lambda x, _: x)\n",
    "    meas = measurement_model.measure(reference)\n",
    "\n",
    "    # 全 1 掩膜，表示全部位置都有 anchor。\n",
    "    mask_tensor = torch.ones_like(reference[:, :1])\n",
    "    ref_norm = reference * 2 - 1\n",
    "    anchor_tokens = var.vae_proxy[0].img_to_idxBl(ref_norm, v_patch_nums=var.vae_quant_proxy[0].v_patch_nums)\n",
    "    token_constraints = []\n",
    "    for si, pn in enumerate(var.vae_quant_proxy[0].v_patch_nums):\n",
    "        m_stage = torch.nn.functional.interpolate(mask_tensor, size=(pn, pn), mode=\"area\")\n",
    "        m_stage = (m_stage > 0.5).squeeze(1)\n",
    "        token_constraints.append({\"mask\": m_stage.reshape(mask_tensor.shape[0], -1), \"idx\": anchor_tokens[si]})\n",
    "\n",
    "    cfg_params = PosteriorGuidanceConfig(\n",
    "        cfg_scale=0.0,\n",
    "        grad_scale_min=0.5,\n",
    "        grad_scale_max=2.0,\n",
    "        grad_start_ratio=0.0,\n",
    "        grad_steps=5,\n",
    "        grad_stop_before_stage=5,\n",
    "        top_p=0.0,\n",
    "        top_k=0,\n",
    "    )\n",
    "    sampler = GradientGuidedVARSampler(var_model=var, measurement_model=measurement_model, config=cfg_params)\n",
    "    result = sampler.sample(\n",
    "        measurement=meas,\n",
    "        label_B=-1,\n",
    "        g_seed=seed,\n",
    "        capture_intermediate=False,\n",
    "        capture_token_trace=True,\n",
    "        token_constraints=token_constraints,\n",
    "    )\n",
    "    if len(result) == 3:\n",
    "        recon, _, trace = result\n",
    "    else:\n",
    "        recon, trace = result\n",
    "    masked_recon = measure_op.operator(recon.to(device))\n",
    "    mse_mask = torch.nn.functional.mse_loss(masked_recon, meas)\n",
    "    print(f\"[{name}] MSE: {mse_mask.item():.5f}\")\n",
    "    for info in trace:\n",
    "        diff = (info['cfg_top'] != info['guided_top']).sum().item()\n",
    "        total = info['cfg_top'].numel()\n",
    "        forced = info.get('forced_tokens', 0)\n",
    "        print(\n",
    "            f\"    Stage {info['stage']}: changed {diff}/{total} tokens, \"\n",
    "            f\"grad_norm={info['grad_norm']:.4f}, max_delta={info['max_delta']:.4f}, forced={forced}\"\n",
    "        )\n",
    "    show_tensor(meas, title=f\"{name} Measurement\")\n",
    "    show_tensor(recon, title=f\"{name} Recon\")\n",
    "\n",
    "# 高斯模糊\n",
    "blur_op = GaussianBlurMeasurement(kernel_size=11, sigma=2.0, downsample=1)\n",
    "run_operator_test(blur_op, 'GaussianBlur')\n",
    "\n",
    "# 超分辨率（下采样再对齐）\n",
    "sr_op = SuperResolutionMeasurement(scale=4)\n",
    "run_operator_test(sr_op, 'SuperResolution')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 矩形遮挡 Inpainting 测试\n",
    "\n",
    "再测试一个矩形缺失的 inpainting 任务：掩膜区域为 0 表示未知，其余为已知（硬注入），高频阶段用梯度微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造中心矩形缺失的掩膜\n",
    "rect_h = target_hw // 3\n",
    "rect_w = target_hw // 3\n",
    "top = (target_hw - rect_h) // 2\n",
    "left = (target_hw - rect_w) // 2\n",
    "rect_mask = MaskingMeasurement.rectangular(\n",
    "    h=target_hw, w=target_hw, top=top, left=left, height=rect_h, width=rect_w, device=device\n",
    ")\n",
    "measurement_model = MeasurementModel(operator=rect_mask.operator, filter_fn=lambda x, _: x)\n",
    "measurement = measurement_model.measure(reference)\n",
    "\n",
    "# anchor tokens 只在已知区域（mask==1）硬注入\n",
    "ref_norm = reference * 2 - 1\n",
    "anchor_tokens = var.vae_proxy[0].img_to_idxBl(ref_norm, v_patch_nums=var.vae_quant_proxy[0].v_patch_nums)\n",
    "token_constraints = []\n",
    "for si, pn in enumerate(var.vae_quant_proxy[0].v_patch_nums):\n",
    "    m_stage = torch.nn.functional.interpolate(rect_mask.mask, size=(pn, pn), mode=\"area\")\n",
    "    m_stage = (m_stage > 0.5).squeeze(1)\n",
    "    token_constraints.append({\"mask\": m_stage.reshape(rect_mask.mask.shape[0], -1), \"idx\": anchor_tokens[si]})\n",
    "\n",
    "cfg_params = PosteriorGuidanceConfig(\n",
    "    cfg_scale=0.0,\n",
    "    grad_scale_min=0.5,\n",
    "    grad_scale_max=2.0,\n",
    "    grad_start_ratio=0.0,\n",
    "    grad_steps=5,\n",
    "    grad_stop_before_stage=5,\n",
    "    top_p=0.0,\n",
    "    top_k=0,\n",
    ")\n",
    "sampler = GradientGuidedVARSampler(var_model=var, measurement_model=measurement_model, config=cfg_params)\n",
    "result = sampler.sample(\n",
    "    measurement=measurement,\n",
    "    label_B=-1,\n",
    "    g_seed=seed,\n",
    "    capture_intermediate=False,\n",
    "    capture_token_trace=True,\n",
    "    token_constraints=token_constraints,\n",
    ")\n",
    "if len(result) == 3:\n",
    "    recon, _, trace = result\n",
    "else:\n",
    "    recon, trace = result\n",
    "masked_recon = rect_mask.operator(recon.to(device))\n",
    "mse_mask = torch.nn.functional.mse_loss(masked_recon, measurement)\n",
    "print(f'[Rect Inpaint] MSE: {mse_mask.item():.5f}')\n",
    "for info in trace:\n",
    "    diff = (info['cfg_top'] != info['guided_top']).sum().item()\n",
    "    total = info['cfg_top'].numel()\n",
    "    forced = info.get('forced_tokens', 0)\n",
    "    print(\n",
    "        f\"    Stage {info['stage']}: changed {diff}/{total} tokens, \"\n",
    "        f\"grad_norm={info['grad_norm']:.4f}, max_delta={info['max_delta']:.4f}, forced={forced}\"\n",
    "    )\n",
    "show_tensor(measurement, title='Rect Measurement')\n",
    "show_tensor(recon, title='Rect Recon')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}