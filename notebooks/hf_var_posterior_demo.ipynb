{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR HF 推理与后验采样 Demo\n",
    "\n",
    "本 Notebook 展示了如何：\n",
    "\n",
    "1. 从 Hugging Face (`FoundationVision/var`) 下载官方发布的 VAE 与 VAR 权重；\n",
    "2. 构建 `var_inv` 中自带的 VAR/VQVAE 模型，并使用 `VAR.autoregressive_infer_cfg` 进行标准 CFG 采样；\n",
    "3. 借助 `GradientGuidedVARSampler` + 测量算子，将 VAR 视作“离散扩散”，对部分观测数据执行后验重建，并可视化每个尺度的重建过程。\n",
    "\n",
    "> ⚠️ 运行前请确保你拥有 Hugging Face 的下载权限（可能需要 `huggingface-cli login`）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备依赖与工具函数\n",
    "\n",
    "以下代码导入 `var_inv` 中封装好的模块，并提供若干辅助函数用于读写图片、可视化采样结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "\n",
    "from var_inv.measurements import MaskingMeasurement\n",
    "from var_inv.posterior_sampling import (\n",
    "    GradientGuidedVARSampler,\n",
    "    MeasurementModel,\n",
    "    PosteriorGuidanceConfig,\n",
    ")\n",
    "from var_inv.var_models.models import build_vae_var\n",
    "\n",
    "\n",
    "def load_rgb(path: Path, target_hw: int) -> torch.Tensor:\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    if target_hw is not None:\n",
    "        img = img.resize((target_hw, target_hw), Image.BICUBIC)\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "\n",
    "def tensor_to_pil(t: torch.Tensor) -> Image.Image:\n",
    "    t = t.detach().cpu().clamp(0, 1)\n",
    "    if t.ndim == 4:\n",
    "        t = t[0]\n",
    "    arr = (t.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "\n",
    "def show_tensor(t: torch.Tensor, title: str = \"\") -> None:\n",
    "    pil_img = tensor_to_pil(t)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(pil_img)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_stages(stage_imgs: List[torch.Tensor], ncols: int = 5) -> None:\n",
    "    if not stage_imgs:\n",
    "        return\n",
    "    nrows = math.ceil(len(stage_imgs) / ncols)\n",
    "    plt.figure(figsize=(3 * ncols, 3 * nrows))\n",
    "    for idx, stage in enumerate(stage_imgs):\n",
    "        ax = plt.subplot(nrows, ncols, idx + 1)\n",
    "        ax.imshow(tensor_to_pil(stage))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"Stage {idx+1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 下载 Hugging Face 权重\n",
    "\n",
    "我们以 `VAR-d16` 为例，需要同时下载 `vae_ch160v4096z32.pth` 与 `var_d16.pth`。下载后的文件会缓存在 `var_inv/hf_assets/` 目录，方便重复运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEPTH = 16  # 可切换成 20/24/30/36，对应不同体量的模型\n",
    "REPO_ID = \"FoundationVision/var\"\n",
    "HF_CACHE = Path(\"var_inv/hf_assets\")\n",
    "HF_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "vae_path = hf_hub_download(repo_id=REPO_ID, filename=\"vae_ch160v4096z32.pth\", cache_dir=HF_CACHE)\n",
    "var_path = hf_hub_download(repo_id=REPO_ID, filename=f\"var_d{MODEL_DEPTH}.pth\", cache_dir=HF_CACHE)\n",
    "print(f\"VAE ckpt: {vae_path}\\nVAR ckpt: {var_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建 VAE / VAR 并加载权重\n",
    "\n",
    "`build_vae_var` 会创建和官方实现一致的结构。加载权重时，我们针对不同 checkpoint 格式（`model`/`state_dict`/纯 `state_dict`）做了兼容处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
    "\n",
    "vae, var = build_vae_var(\n",
    "    device=device,\n",
    "    patch_nums=patch_nums,\n",
    "    num_classes=1000,\n",
    "    depth=MODEL_DEPTH,\n",
    "    shared_aln=False,\n",
    "    attn_l2_norm=False,\n",
    ")\n",
    "\n",
    "def load_module_state(module: torch.nn.Module, ckpt_path: str) -> None:\n",
    "    payload = torch.load(ckpt_path, map_location=device)\n",
    "    if isinstance(payload, dict) and \"state_dict\" in payload:\n",
    "        payload = payload[\"state_dict\"]\n",
    "    if isinstance(payload, dict) and \"model\" in payload:\n",
    "        payload = payload[\"model\"]\n",
    "    module.load_state_dict(payload, strict=True)\n",
    "\n",
    "load_module_state(vae, vae_path)\n",
    "load_module_state(var, var_path)\n",
    "\n",
    "vae.eval().requires_grad_(False)\n",
    "var.eval().requires_grad_(False)\n",
    "print(\"Models are ready on\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 直接使用 CFG 采样\n",
    "\n",
    "首先展示最基础的用法：根据 ImageNet 分类标签直接生成图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "label = torch.tensor([207], device=device)  # 例如 \"golden retriever\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    autocast = torch.autocast(device_type=device.type, enabled=device.type == \"cuda\", dtype=torch.float16)\n",
    "    with autocast:\n",
    "        sample = var.autoregressive_infer_cfg(\n",
    "            B=label.shape[0],\n",
    "            label_B=label,\n",
    "            g_seed=seed,\n",
    "            cfg=4.0,\n",
    "            top_k=900,\n",
    "            top_p=0.96,\n",
    "            more_smooth=False,\n",
    "        )\n",
    "\n",
    "show_tensor(sample, title=\"CFG Sampling Result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 观测约束 + 梯度引导后验采样\n",
    "\n",
    "下面示例模拟一个“随机遮挡”的测量：我们取一张现有图片，当作观测 `y = M \\odot x`，其中 `M` 是随机掩膜。`GradientGuidedVARSampler` 会在每个尺度上通过 Gumbel-Softmax 计算梯度，指导 logits 满足测量约束，并记录每个尺度的重建结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = Path(\"diffusion-posterior-sampling/data/samples/00014.png\")  # 可替换成任意 RGB 图\n",
    "target_hw = patch_nums[-1] * vae.downsample  # 16 * 16 = 256\n",
    "reference = load_rgb(reference_path, target_hw)\n",
    "\n",
    "mask = MaskingMeasurement.random(\n",
    "    shape=(1, 1, target_hw, target_hw),\n",
    "    keep_ratio=0.35,\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")\n",
    "measurement_model = MeasurementModel(operator=mask.operator)\n",
    "measurement = measurement_model.measure(reference)\n",
    "\n",
    "cfg_params = PosteriorGuidanceConfig(\n",
    "    cfg_scale=2.0,\n",
    "    grad_scale_min=0.05,\n",
    "    grad_scale_max=0.35,\n",
    "    grad_start_ratio=0.1,\n",
    "    top_p=0.95,\n",
    "    top_k=900,\n",
    ")\n",
    "sampler = GradientGuidedVARSampler(var_model=var, measurement_model=measurement_model, config=cfg_params)\n",
    "\n",
    "result = sampler.sample(\n",
    "    measurement=measurement.to(device),\n",
    "    label_B=label,\n",
    "    g_seed=seed,\n",
    "    capture_intermediate=True,\n",
    ")\n",
    "recon, stage_imgs = result\n",
    "\n",
    "show_tensor(reference, title=\"Ground Truth (x)\")\n",
    "show_tensor(measurement, title=\"Measurement (y = M ⊙ x)\")\n",
    "show_tensor(recon, title=\"Posterior Reconstruction\")\n",
    "visualize_stages(stage_imgs, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上可视化了从 coarse-to-fine 的每个尺度输出，呈现 VAR 作为“离散扩散”时的逐步细化效果。你也可以尝试其他测量（模糊、超分辨率等）或替换标签、随机种子，探索梯度引导对后验采样的影响。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
  "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
